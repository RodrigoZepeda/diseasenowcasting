#' generate_nowcast_dates
#'
#' Generates dates for the backtesting procedure given the start_date, end_date and stride
#'
#' @param start_date start_date
#'
#' @param end_date end_date
#'
#' @param units units
#'
#' @param stride the number of time steps between two consecutive nowcasts
#'
#' @param subsample If an integer, how much to subsample the dates; if NULL then runs all dates.
#'
#' @keywords internal
generate_nowcast_dates <- function(start_date, end_date, ncast, stride, subsample = NULL) {

  if(is.null(start_date)) {
    stop("Error: Missing start date.")
  }
  if(is.null(end_date) ) {
    stop("Error: Missing end date.")
  }

  # Check if the start and end dates are valid
  if(as.Date(start_date) > as.Date(end_date)) {
    stop("Error: start date must be earlier than or equal to end date.")
  }

  # Check if the stride is a positive integer
  if(!is.numeric(stride) || stride <= 0 || (stride %% 1 != 0)) {
    stop("Error: stride must be a positive integer.")
  }

  # Generate the sequence of dates
  units     <- ncast[["data"]][["call_parameters"]][["units"]]
  true_date <- ncast[["data"]][["call_parameters"]][["true_date"]]

  possible_date_seq  <- ncast[["data"]][["original_data"]] |>
    dplyr::distinct_at(true_date) |>
    dplyr::filter(!!as.symbol(true_date) >= as.Date(start_date)) |>
    dplyr::filter(!!as.symbol(true_date) <= as.Date(end_date)) |>
    dplyr::pull()

  date_seq <- seq(from = min(possible_date_seq), to = max(possible_date_seq), by = paste(stride, units))

  # Sample
  if (!is.null(subsample)){
    date_seq <- sort(sample(date_seq, size = min(subsample, length(date_seq))))
  }

  return(date_seq)
}

#' Infer the dates for backtesting
#'
#' Infers the start (initial) or  end date one needs to consider for backtesting
#'
#' @inheritParams backtest
#'
#' @return A date from which backtesting is possible to start or end (respectively)
#'
#' @name infer_date
#'
#' @export
infer_start_date <- function(ncast){

  #Get the minimum date
  ncast_min_date <- ncast[["data"]][["preprocessed_data"]] |>
    dplyr::summarise(!!as.symbol("min") := min(!!as.symbol(ncast[["data"]][["call_parameters"]][["true_date"]]))) |>
    dplyr::pull(!!as.symbol("min"))

  #Get the maximum date
  ncast_max_date <- ncast[["data"]][["preprocessed_data"]] |>
    dplyr::summarise(!!as.symbol("max") := max(!!as.symbol(ncast[["data"]][["call_parameters"]][["true_date"]]))) |>
    dplyr::pull(!!as.symbol("max"))

  #Get the maximum delay
  ncast_delay   <- ceiling(ncast[["data"]][["call_parameters"]][["num_delays"]]/2)

  #Get the units
  ncast_units   <- ncast[["data"]][["call_parameters"]][["units"]]

  #Get the initial day to nowcast = max delay + min date
  if (ncast_units == "weeks"){
    start_date <- ncast_min_date + lubridate::weeks(ncast_delay)
  } else if (ncast_units == "days"){
    start_date <- ncast_min_date + lubridate::days(ncast_delay)
  } else {
    cli::cli_abort("Invalid units: {.val {ncast_units}}")
  }

  #Check the initial day is in nowcast
  if (start_date <= ncast_min_date | now > ncast_max_date) {
    cli::cli_abort(
      "Unable to automatically infer the initial date for backtesting. Please set up the `start_date` manually."
    )
  }

  return(start_date)

}

#' @rdname infer_date
#' @export
infer_end_date <- function(ncast, start_date){

  #Get the minimum date
  ncast_min_date <- ncast[["data"]][["preprocessed_data"]] |>
    dplyr::summarise(!!as.symbol("min") := min(!!as.symbol(ncast[["data"]][["call_parameters"]][["true_date"]]))) |>
    dplyr::pull(!!as.symbol("min"))

  #Get the maximum date
  ncast_max_date <- ncast[["data"]][["preprocessed_data"]] |>
    dplyr::summarise(!!as.symbol("max") := max(!!as.symbol(ncast[["data"]][["call_parameters"]][["true_date"]]))) |>
    dplyr::pull(!!as.symbol("max"))

  #Get the maximum delay
  ncast_delay   <- ceiling(ncast[["data"]][["call_parameters"]][["num_delays"]]/2)

  #Get the units
  ncast_units   <- ncast[["data"]][["call_parameters"]][["units"]]

  #Get the initial day to nowcast = max delay + min date
  if (ncast_units == "weeks"){
    end_date <- ncast_max_date - lubridate::weeks(ncast_delay)
  } else if (ncast_units == "days"){
    end_date <- ncast_max_date - lubridate::days(ncast_delay)
  } else {
    cli::cli_abort("Invalid units: {.val {ncast_units}}")
  }

  #Check the initial day is in nowcast
  if (end_date <= start_date | end_date > ncast_max_date) {
   cli::cli_abort(
     "Unable to automatically infer the dates for backtesting. Please set up the `start_date` and `end_date` manually."
   )
  }

  return(end_date)

}

#' Backtest
#'
#' Compute historical nowcasts for given time period
#'
#' @param ncast A `nowcaster` object generated by [nowcast()]
#'
#' @param start_date An object of datatype \code{Date} indicating the date at which
#' to start the historical nowcasting (first 'now' date to nowcast).
#'
#' @param end_date An object of datatype \code{Date} indicating the date at which
#' to end the historical nowcasting (last 'now' date to nowcast).
#'
#' @param stride Integer variable indicating the number of time steps between
#' two consecutive nowcasts. Default 1 means nowcasting for each date between
#' start and end,
#'
#' @param dates_to_test Specific values of moments `now` to test the nowcast. If `dates_to_test`
#' is given this overrides `start_date`, `end_date` and `stride`.
#'
#' @param retrain Integer variable indicating the number of iterations for which
#' to retrain the model. Default 1 means retraining the model for each nowcast.
#' NOT IMPLEMENTED YET - currently will be retrained at each time step.
#'
#' @param quantiles list of quantiles in [0,1] defining which quantile estimates
#' will be returned
#'
#' @param min_horizon the minimum horizon in [-Inf,0] to keep from each nowcast estimates
#' (e.g. min_horizon=-5 means estimates of up to previous 5 time steps from now will be kept)
#'
#' @param model_name A model name that will be used to identify the results of the
#' backtest with the given parameters in a subsequent call to [backtest_metrics()]
#'
#' @param ... Additional arguments to pass to [update.nowcaster()]
#'
#' @inheritParams nowcast
#'
#' @return A tibble with as many rows as `dates_to_test` are given. Each row represents a different `now`
#' with the following columns:
#' * `now`: The date nowcasted
#' * `true_date`: The column corresponding to the `true_date` (has the `true_date`'s name).
#' * `mean`: The mean estimate of the `nowcast`.
#' * `sd`: The standard deviation estimate of the `nowcast`.
#' * `median`: The median estimate of the `nowcast`.
#' * `x%`: Quantile columns corresponding to the estimated `xth` quantile.
#' * `Strata_unified`: A column containing the strata modeled.
#' * `observed`: The value actually obnserved for that date
#' * `model`: The name of the fitted model
#'
#' @examples
#' # Load the data
#' data(denguedat)
#'
#' # Run a nowcast with very few iterations
#' # change to method = "sampling" when working and remove the iter = 10 (or set to iter = 2000)
#' now <- as.Date("1990-10-01")
#' ncast <- nowcast(denguedat, "onset_week", "report_week", now = now,
#'   method = "optimization", seed = 2495624, iter = 10)
#'
#' # Run a backtest for the model checking the model fit for two dates:
#' btest <- backtest(ncast, dates_to_test = c(as.Date("1990-06-11"), as.Date("1990-06-18")))
#'
#' #The following examples are slow:
#' \dontrun{
#' # Run a backtest for the model automatically selecting 3 possible dates at random
#' btest2 <- backtest(ncast, subsample = 3)
#'
#' # Run a backtest for the model using all possible dates
#' btest3 <- backtest(ncast)
#' }
#' @export
backtest <- function(ncast,
                     start_date    = infer_start_date(ncast),
                     end_date      = infer_end_date(ncast, start_date = start_date),
                     stride        = 1,
                     subsample     = NULL,
                     dates_to_test = generate_nowcast_dates(start_date, end_date, ncast, stride, subsample = subsample),
                     retrain       = 1,
                     quantiles     = c(0.025, 0.05, 0.25, 0.50, 0.75, 0.95, 0.975),
                     min_horizon   = 0,
                     model_name    = NULL,
                     refresh       = 250*rlang::is_interactive(),
                     ...) {

  #Check ncast is a nowcaster
  if (!inherits(ncast, "nowcaster")){
    cli::cli_abort("A {.code nowcaster} object generated by {.help nowcast()} needs to be used.")
  }

  #Default model name
  if (is.null(model_name)){
    model_name <- paste0("model_",format(Sys.time(), "%Y-%m-%d_%Hh%Mm%Ss"),"_", sample.int(.Machine$integer.max,1))
  }

  #Get the true date column
  true_date <- ncast[["data"]][["call_parameters"]][["true_date"]]

  units     <- ncast[["data"]][["call_parameters"]][["units"]]

  pred_table <- NULL
  for(date in dates_to_test) {

    now <- as.Date(date)

    #Refit and use initial values from previous fit
    predictions  <- update.nowcaster(ncast, new_data = ncast[["data"]][["original_data"]], now = now, refresh = refresh, ...)

    pred_summary <- summary.nowcaster(predictions, quantiles=quantiles)

    pred_summary <- dplyr::tibble(now=now, pred_summary)

    pred_summary$horizon <- as.numeric(difftime(pred_summary$onset_week, now, units=units))

    pred_summary <- pred_summary[pred_summary$horizon>=min_horizon,]

    pred_table   <- rbind(pred_table, pred_summary)
  }

  cases_per_date <- ncast[["data"]][["original_data"]] |>
                    dplyr::group_by(!!as.symbol(true_date)) |>
                    dplyr::summarize(!!as.symbol("observed") := dplyr::n(), .groups = "drop")

  backtest_summary <- pred_table |>
    dplyr::left_join(cases_per_date, by = true_date)

  backtest_summary$model <- model_name

  return(backtest_summary)
}


#' Check same columns
#'
#' Checks that the given list of dataframes contains the same columns
#'
#' @param df_list list of dataframes
#'
#' @keywords internal
check_same_columns <- function(df_list) {
  cols <- colnames(df_list[[1]])
  all_same <- all(sapply(df_list, function(df) identical(colnames(df), cols)))
  return(all_same)
}


#' calc_mae
#'
#' Calculates mean absolute error (mae)
#'
#' @param backtest_summary results of [backtest()]
#'
#' @return The Mean Absolute Error for each of the runs in [backtest()].
#'
#' @examples
#' # Load the data
#' data(denguedat)
#'
#' # Run a nowcast with very few iterations
#' # change to method = "sampling" when working and remove the iter = 10 (or set to iter = 2000)
#' now <- as.Date("1990-10-01")
#' ncast <- nowcast(denguedat, "onset_week", "report_week", now = now,
#'   method = "optimization", seed = 2495624, iter = 10)
#'
#' # Run a backtest for the model checking the model fit for two dates:
#' btest <- backtest(ncast, dates_to_test = c(as.Date("1990-06-11"), as.Date("1990-06-18")))
#'
#' # Get the mean absolute error with the scoringutils package
#' if (requireNamespace("scoringutils", quietly = TRUE)){
#'   calc_mae(btest)
#' }
#'
#' @export
calc_mae <- function(backtest_summary) {

  mae_vals <- NULL
  if (requireNamespace("scoringutils", quietly = TRUE)){
    mae_vals <- backtest_summary |>
      dplyr::select(!!as.symbol("predicted") := !!as.symbol("mean"), dplyr::everything()) |>
      scoringutils::as_forecast_point() |>
      scoringutils::score() |>
      scoringutils::summarise_scores(by = c("horizon","Strata_unified","model","now")) |>
      dplyr::select_at(c("model","now","horizon","Strata_unified","ae_point")) |>
      dplyr::rename(!!as.symbol("mse") := "ae_point")
  } else {
    cli::cli_alert_danger("The `scoringutils` package is required to perform this operation. Please install.")
  }

  return(mae_vals)
}

#' calc_ape
#'
#' Calculates the absolute percent error
#'
#' @param backtest_summary results of backtest call
#'
#' @return The Absolute Percent Error for each of the runs in [backtest()].
#'
#' @examples
#' # Load the data
#' data(denguedat)
#'
#' # Run a nowcast with very few iterations
#' # change to method = "sampling" when working and remove the iter = 10 (or set to iter = 2000)
#' now <- as.Date("1990-10-01")
#' ncast <- nowcast(denguedat, "onset_week", "report_week", now = now,
#'   method = "optimization", seed = 2495624, iter = 10)
#'
#' # Run a backtest for the model checking the model fit for two dates:
#' btest <- backtest(ncast, dates_to_test = c(as.Date("1990-06-11"), as.Date("1990-06-18")))
#'
#' # Get the rmse with the scoring utils package
#' if (requireNamespace("scoringutils", quietly = TRUE)){
#'   calc_ape(btest)
#' }
#'
#' @export
calc_ape <- function(backtest_summary) {

  ape_vals <- NULL
  if (requireNamespace("scoringutils", quietly = TRUE)){
    ape_vals <- backtest_summary |>
      dplyr::select(!!as.symbol("predicted") := !!as.symbol("mean"), dplyr::everything()) |>
      dplyr::mutate(sample=1) |>
      scoringutils::as_forecast_point() |>
      scoringutils::score() |>
      scoringutils::summarise_scores(by = c("horizon","Strata_unified","model","now")) |>
      dplyr::select_at(c("model","now","horizon","Strata_unified","ape"))
  } else {
    cli::cli_alert_danger("The `scoringutils` package is required to perform this operation. Please install.")
  }

  return (ape_vals)
}

#' calc_rmse
#'
#' Calculates root mean squared error (rmse)
#'
#' @param backtest_summary results of backtest call
#'
#' @return The Root Mean Squared Error for each of the runs in [backtest()].
#'
#' @examples
#' # Load the data
#' data(denguedat)
#'
#' # Run a nowcast with very few iterations
#' # change to method = "sampling" when working and remove the iter = 10 (or set to iter = 2000)
#' now <- as.Date("1990-10-01")
#' ncast <- nowcast(denguedat, "onset_week", "report_week", now = now,
#'   method = "optimization", seed = 2495624, iter = 10)
#'
#' # Run a backtest for the model checking the model fit for two dates:
#' btest <- backtest(ncast, dates_to_test = c(as.Date("1990-06-11"), as.Date("1990-06-18")))
#'
#' # Get the rmse with the scoring utils package
#' if (requireNamespace("scoringutils", quietly = TRUE)){
#'   calc_rmse(btest)
#' }
#'
#' @export
calc_rmse <- function(backtest_summary) {

  rmse_vals <- NULL
  if (requireNamespace("scoringutils", quietly = TRUE)){
    rmse_vals <- backtest_summary |>
      dplyr::select(!!as.symbol("predicted") := !!as.symbol("mean"), dplyr::everything()) |>
      dplyr::mutate(sample=1) |>
      scoringutils::as_forecast_point() |>
      scoringutils::score() |>
      scoringutils::summarise_scores(by = c("horizon","Strata_unified","model","now")) |>
      dplyr::select_at(c("model","now","horizon","Strata_unified","se_point")) |>
      dplyr::mutate(!!as.symbol("rmse") := sqrt(!!as.symbol("se_point"))) |>
      dplyr::select(-!!as.symbol("rmse"))
  } else {
    cli::cli_alert_danger("The `scoringutils` package is required to perform this operation. Please install.")
  }

  return (rmse_vals)
}

#' calc_wis
#'
#' Calculates weighted interval score (wis)
#'
#' @param backtest_summary results of backtest call
#'
#' @return The Weighted Interval Scoring for each of the runs in [backtest()].
#'
#' @examples
#' # Load the data
#' data(denguedat)
#'
#' # Run a nowcast with very few iterations
#' # change to method = "sampling" when working and remove the iter = 10 (or set to iter = 2000)
#' now <- as.Date("1990-10-01")
#' ncast <- nowcast(denguedat, "onset_week", "report_week", now = now,
#'   method = "optimization", seed = 2495624, iter = 10)
#'
#' # Run a backtest for the model checking the model fit for two dates:
#' btest <- backtest(ncast, dates_to_test = c(as.Date("1990-06-11"), as.Date("1990-06-18")))
#'
#' # Get the rmse with the scoring utils package
#' if (requireNamespace("scoringutils", quietly = TRUE)){
#'   calc_wis(btest)
#' }
#'
#' @export
calc_wis <- function(backtest_summary) {

  #Get the quantiles
  quantile_cols <- colnames(backtest_summary)[grepl(".*\\%", colnames(backtest_summary))]

  #Check median is included
  if (!("50%" %in% quantile_cols)){
    backtest_summary <- backtest_summary |>
      dplyr::rename(!!as.symbol("50%") := !!as.symbol("median"))

    quantile_cols <- c(quantile_cols, "50%")
  }

  wis_vals <- NULL
  if (requireNamespace("scoringutils", quietly = TRUE)){
    wis_vals <- backtest_summary |>
      tidyr::pivot_longer(cols = quantile_cols, names_to = 'quantile_level', values_to = 'predicted') |>
      dplyr::mutate(!!as.symbol("quantile_level") := as.numeric(stringr::str_remove_all(!!as.symbol("quantile_level"), "\\%"))/100)  |>
      scoringutils::as_forecast_quantile() |>
      scoringutils::score() |>
      scoringutils::summarise_scores(by = c("horizon","Strata_unified","model","now"))
  } else {
    cli::cli_alert_danger("The `scoringutils` package is required to perform this operation. Please install.")
  }

  return (wis_vals)
}

#' backtest_metrics
#'
#' Compute metrics for given backtest results
#'
#' @param ... Results of calls to backtest.
#'
#' @param metrics list of metrics which should be calculated.
#' Currently supporting: 'mae' (mean absolute error), 'rmse' (root mean squared error),
#' and 'wis' (weighted interval score)
#'
#' @param horizons vector of horizons for which the metrics be calculated.
#' Default is to calculate metrics only for horizon 0 (the nowcast).
#'
#' @examples
#' #These examples require the `scoringutils` function
#' if (requireNamespace("scoringutils", quietly = TRUE)){
#'
#' # Load the data
#' data(denguedat)
#'
#' # In this example we will test two models
#' now    <- as.Date("1990-10-01")
#' ncast1 <- nowcast(denguedat, "onset_week", "report_week", now = now,
#'   method = "optimization", seed = 2495624, iter = 10)
#'
#' ncast2 <- nowcast(denguedat, "onset_week", "report_week", now = now,
#'   method = "optimization", seed = 2495624, iter = 10, dist = "Normal")
#'
#' # Run a backtest for each of the models
#' btest1 <- backtest(ncast, dates_to_test = as.Date("1990-06-11"), model_name = "Classic")
#' btest2 <- backtest(ncast, dates_to_test = as.Date("1990-06-11"), model_name = "Normal")
#'
#' # Compare the models to select the best model
#' backtest_metrics(btest1, btest2)
#' }
#' @export
backtest_metrics <- function(..., metrics = c("mae","rmse","wis"), horizons = 0){

  ##Check the models are compatible
  if(!check_same_columns(list(...))){
      cli::cli_abort('Models cannot be compared - different column names in elements of backtest_summary')
  }

  backtest_summary <- dplyr::bind_rows(...)


  #Check the summary
  backtest_summary <- backtest_summary |>
    dplyr::filter(!!as.symbol("horizon") %in% horizons)


  #Get the different strata and models
  now     <- backtest_summary |> dplyr::distinct(!!as.symbol("now")) |> dplyr::pull()
  models  <- backtest_summary |> dplyr::distinct(!!as.symbol("model")) |> dplyr::pull()
  stratas <- backtest_summary |> dplyr::distinct(!!as.symbol("Strata_unified")) |> dplyr::pull()

  metrics_table <- tidyr::expand_grid(horizon=horizons, Strata_unified=stratas, model=models,now=now)

  for(metric in metrics) {

    #Calculate the metric
    metric_results <- switch(
      metric,
      mae  = calc_mae(backtest_summary),
      rmse = calc_rmse(backtest_summary),
      wis  = calc_wis(backtest_summary),
      cli::cli_abort("Unsupported metric: {.val {metric}}.")
    )
    metrics_table <- dplyr::left_join(metrics_table, metric_results, by=c('horizon','Strata_unified','model','now'))
  }
  metrics_table <- metrics_table |>
    dplyr::arrange(!!as.symbol("model"),!!as.symbol("horizon"))

  return(metrics_table)
}
